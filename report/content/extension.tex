\chapter{Extension} \label{chp:extension}

Our extension to SPL concerns the addition of custom, user-defined
record types. The custom record types generally resemble the record types of
Haskell, as seen in the preceding chapters, in particular e.g. the state for our
typing monad and code generation monad.
The syntax that we support also resembles that of SPL's built-in polymorphic
list and tuple type, as our user-defined record types also use field selectors
to access and destructively update the fields of a record instance.

We illustrate the syntax and features of the custom record types in
\cref{sec:ext-syntax-features}, and then proceed to discuss the changes we made
in each stage of our compiler, starting with the lexer and parser in
\cref{sec:ext-parsing}, the desugaring and typing stage in \cref{sec:ext-typing},
and finally the code generation in \cref{sec:ext-codegen}.

\section{Syntax and Features} \label{sec:ext-syntax-features}
In the following, we will use the running example of arithmetic expressions in
two variables $x$ and $y$. The corresponding type is declared as follows in our
syntax:
\begin{lstlisting}[language=SPL]
  data AExp {
    Add(ladd : AExp, radd : AExp),
    Mul(lmul : AExp, rmul : AExp),
    Neg(neg : AExp),
    Lit(lit : Int),
    VarX(), VarY()
  }
\end{lstlisting}

Such \emph{data declarations} must be given at the top level of the program,
prior to the global variable declarations and function declarations.
The above declaration defines a new custom data type \spl{AExp}, along with the
six \emph{constructors} \spl{Add}, \spl{Mul}, \spl{Neg}, \spl{Lit}, \spl{VarX}
and \spl{VarY}, expressing integer addition, multiplication, negation, literals,
and integer variables $x$ and $y$.
For the fields of each constructor (if present), \emph{field selectors} are
defined, which we can use much like \spl{.hd}, \spl{.tl}, \spl{.fst} and
\spl{.snd} to project out the corresponding field from an instance of the type,
as well as destructive updates to the field entries.

Let us now take a look at how these constructors and selectors can be used:
\begin{lstlisting}[language=SPL]
  var a = Add(Lit(1), Lit(1)); // 1 + 1
  var b = Mul(Lit(2), Lit(10)); // 2 * 10
  var res = Mul(VarX(), VarY()); // x * y
  var c = Add(y, a.ladd); // 2 * 10 + 1
  res.lmul = a; // (1 + 1) * y
  res.rmul = c; // (1 + 1) * (2 * 10 + 1)
\end{lstlisting}
%
As one would expect, we can construct instances \spl{AExp} by calling the
constructors much like functions, with the fields given by the constructor
arguments, e.g. \spl{1} in \spl{Lit(1)}. The fields of \spl{Add}, \spl{Mul} and
\spl{Neg} are themselves of type \spl{AExp}, i.e. we can nest \spl{AExp}
instances recursively, like in \spl{Add(Lit(1), Lit(1))}.
The last three lines illustrate how we can use record dot syntax to e.g. select
the left entry from the \spl{Add} instance stored in \spl{a}, or to overwrite
the left and right entry of \spl{res}.

\paragraph{Expressiveness and infinite types}
Much as in Haskell, our custom record types generalise combined sum and product
types: \code{AExp} constitutes a sum type, where the variants are given by the
six constructors. Each of the variants in turn corresponds to an $n$-tuple of
the field types, i.e. a product type. We can make this explicit by writing
\spl{AExp} as a recursive type of the form $\mu \alpha. \tau$ as follows:
\[ \code{AExp} \simeq \mu \alpha.\
    (\alpha \times \alpha) + (\alpha \times \alpha) + \alpha + \code{Int} + \mathbf{1} + \mathbf{1} ,\]
%
Here, $\mathbf{1}$ denotes the unit type, and each component of the sum type
correspond to one of constructors (in the same order as the declaration).
The occurrences of $\alpha$ refer to the recursive type itself, that is, we can
repeatedly unfold such a recursive type $\mu\alpha.\tau$ by substituting
$\alpha$ with $\mu\alpha.\tau$ in $\tau$.

The above serves to illustrate how the custom data/record types actually
increase the expressiveness of SPL: they allow us to declare such infinite,
self-referential data types. Infinite types are not available in SPL otherwise,
except for the special case of the list type \spl{[$\tau$]}, which we can view
as being defined by
$\code{[$\tau$]} \eqdef (\tau \times \code{[$\tau$]}) + \mathbf{1}$
(i.e. head and tail, or the empty list).

For instance, SPL cannot express the type of \emph{rose trees}, which we briefly
touched on in \cref{sec:intro-lang-choice}. For a rose tree of integers, a node
is given by an integer label, along with a list/sequence of subtrees, which are
again nodes as just described.

We might try to emulate this in SPL as follows:
\begin{lstlisting}[language=SPL]
  var exTree123 = (1, (2,[]) : (3,[]) : []);
  /*  1
     / \
    2   3 */
\end{lstlisting}
%
However, the above code does not typecheck: it requires unifying some type
variable $\alpha$ with \spl{(Int,[$\alpha$])}, which violates the occurs check.

With our extension, we can express integer rose trees using a custom data declaration:
\begin{lstlisting}[language=SPL]
  data RoseTreeInt {
    Node(label : Int, forest : [RoseTreeInt])
  }
\end{lstlisting}
%
Using the \spl{Node} constructor rather than tuples, our tree instance from
earlier now typechecks:
\begin{lstlisting}
  var exTree123 = Node(1, Node(2,[]) : Node(3,[]) : []);
\end{lstlisting}


\paragraph{Constructor predicates}
Our custom data types make both their introduction forms and elimination forms
explicit by the constructors and field selectors, respectively.
However, we also need a way of testing which variant of a data type we are
dealing with in order to safely access the fields. Returning to our example of
arithmetic expressions, a function to e.g. print or evaluate an expression would
need to perform a case distinction on the possible forms of the input of type
\spl{AExp}.

Our solution to this is arguably somewhat of a hack, although it does follow the
approach used for SPL's built-in list type. Much like the \spl{isEmpty}
function, we provide the user with a predicate function for each variant of a
data type. For example, for the \spl{Add} constructor we provide a function
\spl{isAdd} of type \spl{AExp -> Bool}, which checks if its argument is
constructed with \spl{Add}.
Using these \emph{constructor predicates}, we can e.g. recursively evaluate an
arithmetic expression for a given valuation of $x$ and $y$:
\begin{lstlisting}[language=SPL]
  evaluate(a,x,y) :: AExp Int Int -> Int {
    if (isAdd(a))  { return evaluate(a.ladd,x,y) + evaluate(a.radd,x,y); } else {
    if (isMul(a))  { return evaluate(a.lmul,x,y) * evaluate(a.rmul,x,y); } else {
    if (isNeg(a))  { return - evaluate(a.neg,x,y); } else {
    if (isLit(a))  { return a.lit; } else {
    if (isVarX(a)) { return x; }
    else { return y; }}}}}
  }
\end{lstlisting}

Clearly, the nested if-statements are not an elegant solution, and it would be
nicer to have some `case of' or `switch' syntax for the multi-way case
distinction.
An even nicer solution would be to support pattern matching, with a pattern
syntax that allows binding the fields to local identifiers, and also e.g.
testing them for equality with a given value, or ignoring them altogether if
a wildcard pattern is used.



\section{Lexing and Parsing} \label{sec:ext-parsing}

We extend our parse AST representation with the following nodes:
\begin{minted}{haskell}
  data DataDecl = DataDecl Loc T.Text [DataConstr]
  data DataConstr = DataConstr Loc T.Text [(T.Text, Type)]
\end{minted}
%
At the top level (\haskell{Program}), we include a list of \haskell{DataDecl}.
The only other changes to the parse AST are that
\begin{itemize}
  \item a field can now be given by \haskell{Selector T.Text}, i.e. the field
        name can be a custom string, and
  \item the expression syntax includes a constructor call node, consisting of
        the constructor name of type \haskell{Text}, and the constructor
        arguments, given by \haskell{[Expr]}.
\end{itemize}

\paragraph{Naming convention}
Aside from adding the \spl{data} keyword, there is another noteworthy change to
the lexing stage: we need a way to distinguish constructor calls from function
calls in our grammar, and similarly for type variables and data types.
We want constructor and function calls to both use the format
$f$\spl{($...$)}. The overlap in the type grammar stems from type variables
and data type names both being given by strings/names.

We follow the convention of Haskell (and other languages) of using lowercase
strings---we call these \emph{identifers}---for functions and function
arguments, and variables, while uppercase strings---which we call
\emph{names}---are reserved for constructors and data types.
This naming convention allows us to already distinguish identifiers and
names in the lexer, where we produce either an \haskell{IdToken} or a
\haskell{NameToken}.

\paragraph{Parsing}
These two separate token types allow our parser to easily distinguish the
overlapping cases described above.
The parsing of data declarations, constructor calls, and field selectors is
otherwise straightforward. We add a new function \code{nameP} for parsing a
\haskell{NameToken} and a parser function for data declarations.
In the expression grammar, we extend the $\NT{Atom}$ level with constructor
calls $C\code{(}...\code{)}$. In contrast to function calls, a constructor
call cannot appear as a statement.


\section{Desugaring and Typing} \label{sec:ext-typing}

Constructor calls and record field selectors in expressions are desugared to
function calls, for which we extend the definition of \haskell{FunName} as
follows:
\begin{minted}{haskell}
  data FunName = Name T.Text | CtorCall T.Text | Selector T.Text | ... | IsEmpty | Print
\end{minted}

Much like for the unary and binary operators, built-in field selectors and
built-in functions, this allows a more uniform treatment in the typing algorithm
and during code generation.

In the typing stage, we extend the domain of the global context with
constructor and selector names:
\begin{minted}{haskell}
  data GlobalId = GlobalTermVar T.Text | GlobalFunName T.Text
                | GlobalCtor T.Text | GlobalSelector T.Text
\end{minted}
%
By treating constructors and selectors essentially like functions, our general
infrastructure and typing monad remains otherwise unchanged.

\paragraph{Global environment entries}
We process data declarations by inserting the constructors into the global
environment with their corresponding type scheme:
\begin{minted}[linenos]{haskell}
  checkDataCtor :: Text.Text -> Ctor -> CGen ()
  checkDataCtor declName (Ctor _ cName args) = do
    envInsertCtor cName $ UScheme S.empty (Fun (snd <$> args) (Data declName))
    -- Insert constructor predicate function `is<CName>` of type `<DataType> -> Bool`
    envGlobalInsertFun ("is" <> cName) $ UScheme S.empty (Fun [Data declName] Bool)
    forM_ args (\(selName,ty) -> -- Insert selector schemes
      envInsertSelector selName $ UScheme S.empty (Fun [Data declName] ty))
\end{minted}
%
The above function processes a constructor \haskell{Ctor} in three steps:
\begin{itemize}
  \item On line 3, we extend the global environment with the constructor, where
        the input types are given by the argument types of the constructor, and
        the output type is given by the data type (\code{declName}).
  %
  \item We also need to add the constructor predicate to the environment, which
        is what happens in line 5: the function name generated by prepending
        \haskell{"is"} to the constructor name, while the type is always given
        by \spl{$\langle\mathit{DataName}\rangle$ -> Bool}.
  %
  \item Finally, lines 6 and 7 iterate over the constructor arguments, adding
        the corresponding field selectors to the global environment. Each
        selector has as its domain the data type, and as its range the type of
        the corresponding constructor field.
\end{itemize}

When we encounter a constructor call or field selector in an expression, we
simply look up the type scheme in the global environment, just like for function
calls. If the constructor/selector is not found in the environment, we report an
error for the missing declaration.

\paragraph{Unification and substitution}
Unification of data types is very straightforward: we can only unify a given
data type $\Dat$ with itself, i.e. of the same name, which yields the empty substitution:
\[ \unify(\Dat_1, \Dat_2) \eqdef
    \begin{cases}
      \emptyset , & \text{ if } \Dat_1 = \Dat_2 \\
      \mathsf{Fail} , & \text{ otherwise}
    \end{cases} \]
%
Substituting in a data type has no effect, and the set of free variables is empty:
\begin{align*}
  \Dat.S \eqdef \Dat && \FV(\Dat) \eqdef \emptyset
\end{align*}


\paragraph{Destructive updates}
The only remaining change is for the use of field selectors in destructive
variable updates. There, we proceed again by looking up the type scheme for the
selector, and reporting an error if it has not been declared.
\begin{minted}{haskell}
  envLookupSelector name >>= \case
    Nothing -> throwLocError loc' $ "Could not find selector `" <> name <> "`"
    Just (UScheme _ (Fun [dataTy@(Data _)] outputTy)) -> pure (dataTy,outputTy)
    Just _ -> error $ "Selector `" <> T.unpack name <> "` does not map out of data type!"
\end{minted}
%
We expect the type scheme to be of the form
\spl{$\langle\mathit{DataName}\rangle$ -> $\tau$}, otherwise we have encountered
an (internal) compiler error.
Next, we unify the output type $\tau$ with the type for the left-hand
side of the assignment (after possibly applying subsequent field selectors), while
we unify the input type with the type of the variable (after applying any
preceding field selectors).
To return to our running example \code{AExp}:
\begin{lstlisting}[language=SPL]
  var x = (True, Lit(1):[]);
  x.snd.hd.lit = 2;
\end{lstlisting}
%
Here, the type of \spl{x.snd.hd}, given by \spl{AExp}, is unified with the input type of
the \spl{.lit} selector, which has type \spl{AExp -> Int}.
The output type of \spl{.lit} is unified with the type of \spl{2}, which is of
course also \spl{Int}.



\section{Code Generation} \label{sec:ext-codegen}

Roughly speaking, the code generation for custom data types generalises the way
we handle the built-in polymorphic list and tuple types.
Instances of a data type are, in general, composed of multiple fields.
Much like for lists and tuples, we store the data itself on the heap, and hold
a pointer to the heap location on the stack.

Constructor calls are handled similarly to the `\spl{:}' (cons) operator and the
tuple constructor \spl{($-$,$-$)}: we compute all entries on the stack, and then
store them block-wise to heap using the \code{stmh} instruction.
Since all data is represented by a single stack entry, the size of the block is
simply given by the number of constructor arguments.

\paragraph{Distinguishing variants}
The main question regarding the representation of the custom data types is how
we ensure that we can distinguish the different variants of a given data type.
More specifically, we need to consider how we can automatically generate the
constructor predicate functions that test for a certain variant.
For lists, we only have two cases, and represent the empty list by a null
pointer on the stack. The code generated for \spl{isEmpty} then simply checks
if the stack entry holds the null pointer.

This approach does not scale to general data types though, e.g. the \spl{AExp}
type from earlier:
%
\begin{lstlisting}[language=SPL]
  data AExp {
    Add(ladd : AExp, radd : AExp),
    Mul(lmul : AExp, rmul : AExp),
    Neg(neg : AExp),
    Lit(lit : Int), VarX(), VarY()
  }
\end{lstlisting}
%
Here, we have two variants that have more than one field, and thus need to be
stored on the stack, namely \spl{Add} and \spl{Mul}.
Since \spl{Add} and \spl{Mul} are both represented by heap locations on the
stack the only way we can distinguish them is by using an additional label entry
on the stack that identifies the respective variant.
We can simply start at 0 and enumerate the constructors, i.e. \spl{Add} gets
label 0, and \spl{Mul} gets label 1.

In the case of \spl{Neg} and \spl{Lit}, it may seem like we can store the single
field directly on the stack rather than the heap, but again, this would prevent
us from distinguishing the variants, as e.g. the field of \spl{Neg} may be given
by a heap location, but so are the variants \spl{Add} and \spl{Mul}. To
circumvent this, we must also store the fields for \spl{Neg} and \spl{Lit} on
the heap, and label them with 2 and 3, respectively.

For \spl{VarX} and \spl{VarY}, we could indeed use a special out-of-bounds
pointer on the stack. We would then always need to check for those pointers
first, and only then can we distinguish the remaining variants by loading their
label from the heap.
With more constructors, this gets rather inefficient, so we instead choose a
uniform representation, where all variants are stored as a heap pointer which
points to the heap data, consisting of at least the label, and possibly also the
field entries.

\paragraph{Heap allocation example}
To illustrate the representation that we use, let us take a look at how we store
the following nested expression:
\begin{lstlisting}[language=SPL]
  var a = Add(Lit(42), VarX());
\end{lstlisting}
%
The generated SSM code performs the following steps:
\begin{itemize}
  \item First, the arguments of \spl{Add} are computed: 42 is loaded to the
        stack, then the label for \spl{Lit} (i.e. 3), and both are stored to the
        heap using the \code{stmh} instruction.
  \item Next, the label for \spl{VarX} (i.e. 4) is loaded and stored to the heap.
  \item The entries of \spl{Add} are now at the top of the stack. The label for
        \spl{Add} (i.e. 0) is loaded, and all three entries are stored to the
        heap, again using \code{stmh}.
\end{itemize}

The above operations result in the heap layout shown in \cref{fig:heap-layout-example}.
%
After storing to the heap, the address at the stack pointer points to the
final entry, which is the label. Data type instances are thus always represented
on the stack by the location of their label, which lets us load and check the
label without needing to offset the address first.


\begin{figure}[t]
  \centering
  \begin{tabular}{|l|l|l|}
    \hline
    \textbf{Address} & \textbf{Value} & \textbf{Comment} \\
    \hline
    \code{0X0007D0} & \code{0X00002A} & \code{Lit}, \code{lit} entry \\
    \code{0X0007D1} & \code{0X000003} & \code{Lit} label  \\
    \code{0X0007D2} & \code{0X000004} & \code{VarX} label \\
    \code{0X0007D3} & \code{0X0007D1} & \code{Add}, \code{ladd} entry \\
    \code{0X0007D4} & \code{0X0007D2} & \code{Add}, \code{radd} entry \\
    \code{0X0007D5} & \code{0X000000} & \code{Add} label \\
    \hline
  \end{tabular}
  %
  \caption{Heap layout (excerpt) after allocating expression \code{Add(Lit(42), VarX())}}
  \label{fig:heap-layout-example}
\end{figure}

\paragraph{Implementation}
Implementing the approach described so far requires some additional data
structures in our code generation stage. We extend the state of our code
generation monad with a field \code{ctorMap} of type \haskell{Map Text CtorData},
i.e. a map associating constructor names to instances of \haskell{CtorData},
which is defined as follows:
\begin{minted}{haskell}
  data CtorData = CtorData { label :: Int, fieldCount :: Int }
\end{minted}
%
For each constructor, the map thus contains the label (as in the example above),
and the number of fields, which dictates how many stack entries we need to store
to the heap for the constructor call.
In addition, we use a field \code{selectorMap} of type \haskell{Map Text Int}
which associates to each field the respective heap offset, which is needed for
loading and storing with the field selectors.

We then process the constructor calls of each data declaration as follows:
\begin{minted}[linenos]{haskell}
  codegenCtor :: (Ctor,Int) -> Codegen SSMProgram
  codegenCtor (ctor@(Ctor _ cName args), cLabel) = do
    let fieldOffsets = zip (reverse (fst <$> args)) [(-1::Int),-2..]
    forM_ fieldOffsets codegenSelector
    insertCtorData cName $ CtorData cLabel (length args)
    codegenPredicate ctor cLabel
    where
      codegenSelector :: (T.Text,Int) -> Codegen ()
      codegenSelector (name,offset) = insertSelector name offset
\end{minted}

The heap location on the stack refers to the label entry, which thus has offset
0. Since the fields of the constructor are stored before the label, these have
the offsets $-n,\dots,-1$ for a constructor with $n$ fields.
Line 3 generates the corresponding name-offset pairs by zipping the list
enumeration \haskell{[-1,-2..]} with the reversed list of constructor field
names. The resulting pairs are then passed to \code{codegenSelector}, which
inserts them into \code{selectorMap}.

The function \code{codegenPredicate} generates the predicate function for the
constructor \code{ctor} based on the integer label \code{cLabel}. In the case
of \spl{Lit}, the following SSM code is generated:
\begin{lstlisting}[numbers=left]
  isLit:
    ldl 1
    ldh 0
    ldc 3
    eq
    str RR
    ret
\end{lstlisting}
%
First, the argument to the function is loaded with an offset of 1 from the mark
pointer (line 2); then, the label is loaded from the stack (line 3), and the
label 3 identifying \spl{Lit} is loaded (line 4).
The two values are compared (line 5), resulting in a Boolean entry at the stack
pointer, which is stored to the return register before returning from the
subroutine.


\paragraph{Destructive updates}
As for lists and tuples, the field selectors of custom data types can also be
used in assignments to perform destructive updates, for example:
\begin{lstlisting}[language=SPL]
  var a = Add(Lit(20),Lit(2));
  a.ladd.lit = 40;
\end{lstlisting}
%
We extend the approach we use in the code generation stage, where we traverse
the field selectors from left to right.
At each step, we load from the address at the top of the stack, and then
possibly apply an offset to the result.
With the addition of the custom field selectors, the code for loading the next
location is:
\begin{minted}{haskell}
  case field of
    Head -> pure (program ++ [LoadAddress 0, AddOffset $ -1], ident)
    ...
    (SelField name) -> do
      offset <- lookupSelector name
      let loadProgram = LoadAddress 0 : [AddOffset offset]
      pure (program ++ loadProgram, ident)
\end{minted}

Here is where the \code{selectorMap} comes into play, as we use it to look up
the offset for the respective field. Since the field offsets are given by
$-n,\dots,-1$, the offset is always non-zero, so we always include the
\haskell{AddOffset} (that is, \code{ldaa}) instruction.

In the example assignment \spl{a.ladd.lit = 40;}, we start by loading the
(heap or stack) address corresponding to \spl{a}. We then load from that
address, which gives us the heap location of the \spl{Add} instance. We apply an
offset of $-2$ to get the location of the \spl{ladd} entry.
Next, we load from that address, resulting in the heap location of the \spl{Lit}
entry, and offset with $-1$. We now have the location of the \spl{lit} field at
the top of the stack, and store the new value of $40$ to that location.



% \begin{itemize}
  % \item Again, ctors and selectors are represented as (special cased) function
  %       calls
  % \item Main challenge/question: How to represent data type instances? Since we
  %       use boxing for all composite data, we want to store the fields on the
  %       heap, and keep just a heap location on the stack.
  % \item How to identify different variants (predicate functions)? Not an issue
  %       with list type, since empty list can be represented by null pointer on
  %       stack. With custom data types, multiple variants may only fit on the
  %       heap, so we need to add a label on the heap which identifies the variant.

  % \item The predicate functions need to be `variant-agnostic', i.e. work the
  %       same for all variants. We could arguably represent ctors w/ no args as
  %       a special value on the stack, but then we would always need to check
  %       those prior to loading the label, which could get quite inefficient

  % \item Hence, we instead choose to always store the label on the stack, even if
  %       there are no fields. Then we can just load the label and check for
  %       equality with the variant label.
  %       Include the code we generate for ctor predicates?
  %       Yes, example given for Lit constructor.

  % \item Ctor calls are basically a generalisation of cons and the tuple
  %       constructors, that is, we compute all the arguments on the stack, and
  %       then store the block to the heap (w/ stmh), along with the label that
  %       identifies the variant (discussed above).

  % \item Destructive updates: We load the heap address for the variable on the
  %       stack, and then offset it based on the field selector.
  %       All fields have size 1 on the heap, so we just offset by $i$ for the $i$-th
  %       field (or $-i+1$, or whatever).
  %       Once we reach the end of the selector chain, we store the value to the
  %       address at the SP.

  % \item Use \spl{AExp} example again, and give an example heap representation as
  %       a table figure.
% \end{itemize}
